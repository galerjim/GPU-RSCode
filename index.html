<!doctype html>
<html lang="en">

	<head>
		<meta charset="utf-8">

		<title>Accelerate Reed-Solomon on GPUs</title>

		<meta name="description" content="Accelerate Reed-Solomon on GPUs">
		<meta name="author" content="Shuai YUAN">

		<meta name="apple-mobile-web-app-capable" content="yes" />
		<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />

		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<link rel="stylesheet" href="css/reveal.min.css">
		<link rel="stylesheet" href="css/theme/serif.css" id="theme">

		<!-- For syntax highlighting -->
		<link rel="stylesheet" href="lib/css/zenburn.css">

		<!-- For displaying theorems in LaTeX ways -->
		<link rel="stylesheet" href="css/theorems.css">

		<!-- For printing -->
		<!--
		<link rel="stylesheet" href="css/print/pdf.css">
		-->

		<!-- If the query includes 'print-pdf', use the PDF print sheet -->
		<script>
			document.write( '<link rel="stylesheet" href="css/print/' + ( window.location.search.match( /print-pdf/gi ) ? 'pdf' : 'paper' ) + '.css" type="text/css" media="print">' );
		</script>

		<!--[if lt IE 9]>
		<script src="lib/js/html5shiv.js"></script>
		<![endif]-->
	</head>

	<body>

		<div class="reveal">

			<!-- Any section element inside of this container is displayed as a slide -->
			<div class="slides">
				<section>
					<h2>Accelerate Reed-Solomon Codes on GPUs</h2>
					<br>
					<p>
					<h3><a href="http://yszheda.github.io">Shuai YUAN</a> <br><a href="lsalab.cs.nthu.edu.tw/home">LSALab</a></h3>
					</p>
				</section>

				<section>
					<h2>Overview</h2>
					<ul>
						<li></li>
					</ul>

					<aside class="notes">
						Oh hey, these are some notes. They'll be hidden in your presentation, but you can see them if you open the speaker notes window (hit 's' on your keyboard).
					</aside>
				</section>

				<!-- Example of nested vertical slides -->
				<section>
					<section>
						<h2>Background</h2>
						<p>
						</p>
					</section>
					<section>
						<h2>Why Fault-Tolerance?</h2>
						<p align="left">
In a RAID-like system, storage is distributed among several devices, the probability of one of these devices failing becomes significant:
						</p>
						<p align="left">
If the MTTF (mean time to failure) of one device is $P$, then the MTTF of a system of $n$ devices is $\dfrac{P}{n}$.
						</p>
						<p>
Therefore in such systems, fault-tolerance must be taken into account.
						</p>
					</section>
					<section>
						<h2>Why Reed-Solomon Codes?</h2>
						<table>
						<tr align="center">
						<td>
						<img src="./images/dot-graph/e-c.png">
						</td>
						<td>
						<img src="./images/dot-graph/replica.png">
						</td>
						</tr>
						<tr align="center">
						<td>
						Reed-Solomon Code (n=4, k=2)
						</td>
						<td>
						Replication
						</td>
						</tr>
						</table>
						<p>
						Save 50% space!
						</p>
					</section>
					<section>
						<h2>Reed-Solomon Code Overview</h2>
						<table>
						<tr align="center">
						<td>
						<img src="./images/dot-graph/encode.png">
						</td>
						<td>
						<img src="./images/dot-graph/decode.png">
						</td>
						<tr align="center">
						<td>
						Reed-Solomon Encoding
						</td>
						<td>
						Reed-Solomon Decoding
						</td>
						</tr>
						</tr>
						</table>
					</section>
					<section>
						<h2>Reed-Solomon Coding Mechanism</h2>
					</section>
					<section>
						<h2>Reed-Solomon Encoding Mechanism</h2>
						<p>
Given file $F$:
divide it into $k$ equal-size native chunks: 
$F = [F_{i}]_{i=1,2,\dots,k}$.
Encode them into $(n-k)$ code chunks: 
$C = [C_{i}]_{i=1,2,\dots,n-k}$.

Use Encoding Matrix $EM_{(n-k) \times k}$ to produce code chunks:
$$
C^{T} = EM \times F^{T} 
$$
$C_{i}$ is the linear combination of $F_{1}, F_{2}, \dots, F_{k}$.
						</p>
					</section>
					<section>
						<h2>Reed-Solomon Encoding Mechanism</h2>
						<p>
In our case,
\begin{align}
\begin{array}{rcl}
F &=& \begin{pmatrix} A & B \end{pmatrix} \\
EM &=& 	\begin{pmatrix}
		  1 & 1 \\
		  1 & 2 \\
		\end{pmatrix} \\
%C &=& \begin{pmatrix} A & B & A+B & A+2B \end{pmatrix}
C^{T} &=& \begin{pmatrix} 1 & 1 \\  1 & 2 \\ \end{pmatrix} \times \begin{pmatrix} A \\ B \end{pmatrix} \\
&=& \begin{pmatrix} A+B \\ A+2B \end{pmatrix}
\end{array}
\end{align}
						</p>
					</section>
					<section>
						<h2>Reed-Solomon Encoding Mechanism</h2>
						<p align="left">
Let $P = [P_{i}]_{i=1,2,\dots,n} = [F_{1}, F_{2}, \dots, F_{k}, C_{1}, C_{2}, \dots, C_{n-k}]$ be the $n$ chunks in storage, 
$EM' = \begin{pmatrix} I \\ EM \end{pmatrix}$,
Here 
$$
I = \begin{pmatrix} 
  1 & 0 & \ldots & 0 \\ 
  0 & 1 & \ldots & 0 \\
  \vdots & \vdots & \ddots & \vdots \\
  0 & 0 & \ldots & 1 
\end{pmatrix}
$$
then
\begin{align}
\begin{array}{rcl}
P^{T} &=& EM' \times F^{T} \\
&=& \begin{pmatrix} F^{T} \\ C^{T} \end{pmatrix}
\end{array}
\end{align}
						</p>
					</section>
					<section>
						<h2>Reed-Solomon Encoding Mechanism</h2>
						<p>
In our case,
<small>
\begin{align}
\begin{array}{rcl}
EM' &=& \begin{pmatrix} I \\ EM \end{pmatrix} 
  = \begin{pmatrix}
	1 & 0 \\
	0 & 1 \\
	1 & 1 \\
	1 & 2 \\
	\end{pmatrix} \\	
P^{T} &=& EM' \times F^{T} \\
&=& \begin{pmatrix}
	1 & 0 \\
	0 & 1 \\
	1 & 1 \\
	1 & 2 \\
	\end{pmatrix}
	\times
	\begin{pmatrix} A \\ B \end{pmatrix} \\
	&=& \begin{pmatrix}
	A \\
	B \\
	A+B \\
	A+2B
	\end{pmatrix}
\end{array}
\end{align}
</small>
						</p>
					</section>
					<section>
						<h2>Reed-Solomon encoding Mechanism</h2>
						<p>
$EM'$ is the key of MDS property!
						</p>
						<div class="theorem">
[necessary and sufficient condition]Every possible $k \times k$ submatrix obtained by removing $(n-k)$ rows from $EM'$ has full rank.
<br>equivalent expression of full rank:
<ul>
<li>
rank = $k$
</li>
<li>
non-singular
</li>
<li>
$\vdots$
</li>
</ul>
						</div>
						<p>
Alternative view:

Consider the linear space of $P = [P_{i}]_{i=1,2,\dots,n} = [F_{1}, F_{2}, \dots, F_{k}, C_{1}, C_{2}, \dots, C_{n-k}]$,
its dimension is $k$, and any $k$ out of $n$ vectors form a basis of the linear space.
						</p>
					</section>
					<section>
						<h2>Reed-Solomon encoding Mechanism</h2>
						<p>
Reed-Solomon Codes uses Vandermonde matrix $V$ as $EM$
$$
V =
\begin{bmatrix}
1 & 1 & 1 & \ldots & 1 \\
1 & 2 & 3 & \ldots & k \\
1^2 & 2^2 & 3^2 & \ldots & k^2 \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
1^{(n-k)} & 2^{(n-k)} & 3^{(n-k)} & \ldots & k^{(n-k)}
\end{bmatrix}
$$
						</p>
					</section>
					<section>
						<h2>Reed-Solomon encoding Mechanism</h2>
						<p>
$$
EM' =
\begin{bmatrix}
1 & 0 & 0 & \ldots & 0 \\
0 & 1 & 0 & \ldots & 0 \\
0 & 0 & 1 & \ldots & 0 \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
0 & 0 & 0 & \ldots & 1 \\
1 & 1 & 1 & \ldots & 1 \\
1 & 2 & 3 & \ldots & k \\
1^2 & 2^2 & 3^2 & \ldots & k^2 \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
1^{(n-k)} & 2^{(n-k)} & 3^{(n-k)} & \ldots & k^{(n-k)}
\end{bmatrix}
$$
						</p>
					</section>
					<section>
						<h2>Reed-Solomon encoding Mechanism</h2>
						<p>
<!--
%\begin{displaymath}
%\begin{array}{rcl}
%\textrm{For } i=1,2,\dots,n(n-k) &&\\
%For $i=1,2,\dots,n(n-k)$
%\begin{displaymath}
%\begin{array}{rcl}
%P_{i} &=& ECV_{i} \times F^{T} \\
%&=& \sum_{j=1}^{k(n-k)} \alpha_{i,j}F_{j}
%\end{array}
%\end{displaymath}
%$ECV_{i}$: encoding coeffient vector of $P_{i}$.
-->
Remark:
<ul>
	<li>
All arithmetic operations in Galois Field GF($2^{w}$). Then every number is less than $2^{w}$.
	</li>
	<li>
$EM'$ satisfies MDS property.
	</li>
</ul>
					</section>
					<section>
						<h2>Reed-Solomon Decoding Mechanism</h2>
						<p>
We randomly select $k$ out of $n$ fragments, say $X = [x_{1}, x_{2}, \cdots, x_{k}]^{T}$.

Then we use the coefficients of each fragments $x_{i}$ to construct a $k \times k$ matrix $V'$.

Original data can be regenerated by multiplying matrix $X$ with the inverse of matrix $V'$:

$$
F = V'^{-1} X 
$$
					</p>
					</section>
					<!--
					<section>
						<h2>Optimization Motivation</h2>
					</section>
					-->
					<section>
						<h2>Brief Introduction of Galois Field</h2>
					</section>
					<!--
					<section>
						<h2>Introduction of Galois Field</h2>
						<p class="frame">
Galois field/Finite field GF($p^w$) is a set of $w$ elements closed under addition and multiplication, for which every element has an additive and multiplicative inverse (except for the 0 element which has no multiplicative inverse).
						</p>
						<p class="frame" align="left">
Suppose $n > 1$ is not a prime. Then the set $\{ 0; 1; ...; n \}$ where addition and
multiplication are both performed modulo $n$ is not a field. 
e.g. Let $n = 4$. Then the set $\{ 0; 1; 2; 3 \}$ is indeed closed under addition and multiplication modulo 4, however, the element 2 has no multiplicative inverse (there is no $a \in \{ 0; 1; 2; 3 \}$ such that $2a \equiv 1 (mod 4)$).
						</p>
					</section>
					<section>
						<h2>Introduction of Galois Field</h2>
						<p>
From another aspect, Galois field is a set of all polynomials of degree at most $w-1$.
GF($2^w$) field is constructed by finding a primitive polynomial $q(x)$ of degree $w$ over GF($2$), and then enumerating the elements (which are polynomials) with the generator $x$.
						</p>
					</section>
					-->
					<section>
						<h2>Breif Introduction of Galois Field GF($p^w$)</h2>
						<p class="frame">
Galois field GF($p^w$), where $p$ is a prime and $w$ is a positive integer, is a set of $p^w$ polynomials of degree at most $w - 1$. 
						</p>
						<p class="frame roll-in">
						<ul>
							<li>
The field is <font color="#ff0000">closed under addition and multiplication</font>, for which every element has an additive and multiplicative inverse (except for the 0 element which has no multiplicative inverse).
							</li>
							<li>
there exists an element $\alpha$ in GF($p^w$),
such that
all the non-zero elements of GF($p^w$) can be written as $\alpha^i$ for some integer $i$.
The element $\alpha$ is called the <font color="#ff0000">primitive element</font> or <font color="#ff0000">generator</font> of the GF($p^w$).
The primitive element $\alpha$ has the property of $\alpha^{2^w - 1} = 1$.
							</li>
						</ul>
						</p>
					</section>
					<section>
						<h2>Breif Introduction of Galois Field GF($2^w$)</h2>
						<p align="left">
Among the Galois Fields, the binary extension fields GF($2^w$) are of particular interest in erasure codes due to the byte-based nature of memory in many computer architectures.
						</p>
						<p align="left" class="frame roll-in">
GF($2^w$) is constructed by finding a primitive polynomial $q(x)$ of degree $w$ over GF$(2)={0,1}$, and then enumerating the polynomial elements with a generator.
						</p>
					</section>
					<section>
						<h2>Generation of GF($2^w$)</h2>
						<p align="left" class="frame roll-in">
In GF($2^w$), the polynomial $x$ can be considered a generator.
						</p>
						<p>
Generation of GF($2^w$): 
						</p>
						<p class="frame roll-in">
						<ul> 
							<li>start with the elements 0, 1, and $x$</li>
							<li>continue to enumerate the elements by multiplying the last element by $x$ and taking the result modulo $q(x)$ if it has a degree no less than $w$.</li>
							<li>This enumeration ends at $2^w$ elements – the last element multiplied by $x$ mod $q(x)$ equals 1.</li>
						</ul>
						</p>
					</section>
					<section>
						<h2>Generation of GF($2^w$)</h2>
						<p>
e.g. Generation of GF($2^2$): 
$w = 2$, and $q(x) = x^2 + x + 1$.
						</p>
						<p class="fragment" data-fragment-index="1">
Initial set: $\{ 0; 1; x \}$
						</p>
						<p class="fragment" data-fragment-index="2">
$x^2 \textrm{ mod } q(x) = x + 1$, insert into the set: $\{ 0; 1; x; 1+x \}$.
						</p>
						<p class="fragment" data-fragment-index="3">
$(x+1)x \textrm{ mod } q(x) = 1$, end of enumeration.
						</p>
					</section>
					<section>
						<h2>Breif Introduction of Galois Field GF($2^w$)</h2>
						<p align="left" class="frame roll-in">
Each polynomial elements of GF($2^w$) can be mapped into a binary word $b$ of size $w$ by setting the $i$th bit of $b$ to the coefficient of $x^i$ in the polynomial.
<!--Mapping from polynomial elements of Galois Field into binary elements: equivalent to letting the generator $x = 2$.-->
						</p>
						<p class="fragment">
e.g. GF($2^2$)
						</p>
						<table class="fragment">
							<tr>
								<td>generated element</td>
								<td>polynomial element</td>
								<td>binary element $b$</td>
								<td>decimal representation of $b$</td>
							</tr>
							<tr>
								<td>0</td>
								<td>0</td>
								<td>00</td>
								<td>0</td>
							</tr>
							<tr>
								<td>$x^0$</td>
								<td>1</td>
								<td>01</td>
								<td>1</td>
							</tr>
							<tr>
								<td>$x^1$</td>
								<td>$x$</td>
								<td>10</td>
								<td>2</td>
							</tr>
							<tr>
								<td>$x^2$</td>
								<td>$x+1$</td>
								<td>11</td>
								<td>3</td>
							</tr>
						</table>
						<p class="fragment">
For GF($2^8$), every element can be mapped into a byte.
						</p>
					</section>

				</section>
<!--
				<section>
					<section>
						<h2>Optimization Techniques</h2>
					</section>
				</section>
-->
				<section>
					<section>
						<h2>Accelerate Operations in Galois Field</h2>
					</section>
					<section>
						<h2>Accelerate Operations in Galois Field</h2>
						<ul>
							<li class="fragment">
Addition/subtraction of two elements in GF($2^w$) in this field can be performed by inexpensive bitwise XOR of the elements.
							</li>
							<li class="fragment">
Multiplication of two elements is defined as the multiplication of two polynomials which represents the elements and modulo an irreducible generator polynomial.
							</li>
						</ul>
						<p class="fragment">
						<br>
Therefore, how to accelerate the time-consuming <font color="#ff0000">multiplication</font> over GF($2^w$) will be our focus.
<!--Here we focus on the acceleration of multiplication on Galois Fields.-->
						</p>
					</section>

					<section>
						<h2>GPU Implementation: Loop-based or Table-based?</h2>
					</section>
					<section>
						<h2>Loop-based Method</h2>
					</section>
					<section>
						<h2>Overview of the Loop-based Method</h2>
						<p align="left">
To perform the multiplication of two binary numbers in GF($2^w$), the numbers should be converted to their polynomial elements, multiplied by the polynomials modulo $q(x)$, and then converted back to binary.
<!--Basically, multiplication over Galois Field is polynomial multiplication and taking the result modulo $q(x)$.-->
						</p>
						<p class="fragment">
<font color="#ff0000">Russian peasant multiplication algorithm</font> can be used to turn it into bitwise operations.
						</p>
					</section>

					<section>
						<h2>Russian Peasant Multiplication Algorithm</h2>
						<p>
e.g. Russian peasant multiplication in normal field:
\begin{align}
9 \times 12 &\leadsto (9/2) \times (12 \times 2) + 12 \\
&\leadsto (4/2) \times (24 \times 2) + 12 \\
&\leadsto (2/2) \times (48 \times 2) + 12 \\
&\leadsto (48 \times 2) + 12 \\
&\leadsto 108
\end{align}
						</p>
					</section>

					<section>
						<h2>Russian Peasant Multiplication Algorithm</h2>
						<p>
e.g. Russian peasant multiplication in GF($2^8$):
\begin{align}
(x^3+1) \times (x^3+x^2) &\leadsto (x^2) \times (x(x^3+x^2)) + (x^3+x^2) \\
&\leadsto (x) \times (x(x^4+x^3)) + (x^3+x^2) \\
&\leadsto 1 \times (x(x^5+x^4)) + (x^3+x^2) \\
&\leadsto x^6+x^5+x^3+x^2 (\equiv 108) \\
\end{align}
						</p>
						<p class="fragment roll-in">
Actually multiplication in GF($2^w$) is the same as that in normal field, except that we have to add necessary modulo operations so that the result is smaller than $2^w$.
						</p>
					</section>

					<section>
						<h2>Example Implementation of Russian Peasant Multiplication Algorithm</h2>
						<small>multiply two operands $a$ and $b$ in GF($2^8$):</small>
						<pre><code class="cpp" data-trim contenteditable>
uint8_t gf256_mul(uint8_t a, uint8_t b)
{
  uint8_t result;
  while(b)
  {
    // LSB bit of b is 1
    if(b & 1)
    {
      // Emulate polynomial addition
      result ^= a;
    }
    // Primitive polynomial of GF(2^8):
    // x^8+x^4+x^3+x^2+1
    // which is mapped into 0x1d
    uint8_t prim_poly = 0x1d;
    // Emulate polynomial modulo
    a <<= 1;
    // MSB bit of a is 1
    if (a & 0x80)
    {
        // modulo by prim_poly
        a ^= prim_poly;
    }
    b >>= 1;
  }
  return result;
}
						</code></pre>
						<p class="fragment">
<small>costs at most eight iterations to complete → <font color="#ff0000" class="fragment">computation-bound</font></small>
						</p>
					</section>

					<section>
						<h2>Table-based Methods</h2>
					</section>
					<section>
						<h2>Full Multiplication Table Method</h2>
						<p>
						Pre-compute all the multiplication result in a table.
						Multiplication becomes one table-lookup operation.
						</p>
						<small>e.g. Implementation of full multiplication table method in $GF(2^8)$:</small>
						<pre><code class="cpp" data-trim contenteditable>
uint8_t gf256_mul_table[256][256];
uint8_t gf256_mul(uint8_t a, uint8_t b)
{
  return gf256_mul_table[a][b];
}
						</code></pre>
						<p class="frame roll-in">
						<ul>
										<li>Pros: least computation operations: only one table-lookup.</li>
										<li>Cons:
										<ul>
														<li>large memory consumption: $O(2^w \times 2^w)$ for $GF(2^w)$.</li>
														<li>redundancies in the table: <br>e.g. gf256_mul_table[a][b] = gf256_mul_table[b][a]</li>
										</ul>
										</li>
						</ul>				
						</p>
					</section>
					<section>
						<h2>Double Table/Left-Right Table Method</h2>
						<p>
						Split the full multiplication table of $2^w \times 2^w$ entries into two tables of $2^{w/2} \times 2^w$ entries each.
						<small>
						\begin{align}
						a(x) \times b(x) &= (a_{0} + a_{1}x + ... + a_{w-1}x^{w-1}) \times (b_{0} + b_{1}x + ... + b_{w-1}x^{w-1}) \\
						&= (a_{0} + a_{1}x + ... + a_{w/2-1}x^{w/2-1}) \times (b_{0} + b_{1}x + ... + b_{w-1}x^{w-1}) \\
						&+ (a_{w/2}x^{w/2}  + ... + a_{w-1}x^{w-1}) \times (b_{0} + b_{1}x + ... + b_{w-1}x^{w-1})
						\end{align}
						</small>
						<small>Note: add operations in Galois Field are equivalent to XOR.</small>
						</p>
					</section>
					<section>
						<h2>Double Table/Left-Right Table Method</h2>
						<small>e.g. Implementation of left-right table method in $GF(2^8)$:</small>
						<pre><code class="cpp" data-trim contenteditable>
uint8_t gf256_left_table[16][256];
uint8_t gf256_right_table[16][256];
uint8_t gf256_mul(uint8_t a, uint8_t b)
{
	return (gf256_left_table[(a >> 4) & 0x0f][b]) ^ (gf256_left_table[a & 0x0f][b]);
}
						</code></pre>
						</p>
						<p class="frame roll-in">
						<ul>
										<li>Space complexity: $O(2^{3w/2+1})$ for $GF(2^w)$.</li>
										<li>Computation complexity: 2 table-lookup, 2 AND, 1 XOR, and 1 SHIFT operations.</li>
						</ul>				
						</p>
					</section>
					<section>
						<h2>Log&Exp Table Method</h2>
						<p>
						Every element in a finite field can be represented uniquely by a power of a primitive element $\alpha$, except for 0.
						<br>Observation: $a \times b = exp(log(a) + log(b))$
						</p>
					</section>
					<section>
						<h2>Log&Exp Table Method</h2>
						<p>
						Construct two tables:
						<ul>
										<li>
										exponential table: maps from a binary element $b$ to power $j$ such that $x^j$ is equivalent to $b$.
										</li>
										<li>
										logarithm table: maps from a power $j$ to its binary element $b$ such that $x^j$ is equivalent to $b$.
										</li>
						</ul>
						</p>
						<p>
						Multiplication in $GF(2^w)$ consists of 
						<ul>
										<li>
										looking each binary number in the logarithm table for its logarithm (equivalent to finding the polynomial), 
										</li>
										<li>
										adding the logarithms modulo $2^w-1$ (equivalent to multiplying the polynomial modulo $q(x)$) 
										</li>
										<li>
										looking up exponential table to convert the result back to a binary number.
										</li>
						</ul>
					</section>
					<section>
						<h2>Log&Exp Table Method</h2>
						<small>e.g. Implementation of log-exp table method in $GF(2^8)$:</small>
						<pre><code class="cpp" data-trim contenteditable>
uint8_t gf256_log_table[256];
uint8_t gf256_exp_table[256];
// width of GF(2^8)
const int width = 8;
// number of elements in GF(2^8)
const int NW = 1 << width;
uint8_t gf256_mul(uint8_t a, uint8_t b)
{
  int result;
  if (a == 0 || b == 0)
  {
    return 0;
  }
  result = (gf256_log_table[a] + gf256_log_table[b]) % (NW-1);
  return gf256_exp_table[result];
}
						</code></pre>
						</p>
						<p class="frame roll-in">
						<ul>
										<li>Space complexity: $O(2^w \times 2)$ for $GF(2^w)$.</li>
										<li>Computation complexity: 3 table-lookup, 1 MOD, 1 ADD, and 2 branch operations.</li>
						</ul>				
						</p>
					</section>
					<section>
						<h2>Log&Exp Table Method - Improvement I</h2>
						<p>
						Replace expensive MOD operation with more efficient operations.
						<br>Observation: $(log(a)+log(b)) \in [0, 2^{w+1}-2]$
						</p>
						<p>
						Let $Q = 2^w$, then $log(a), log(b) \in [0,Q-1]$.
						<small>
						<br>
						\begin{equation*}
						(log(a) + log(b)) \% Q = \left\{
						\begin{array}{ll}
						0 & \textrm{if } (log(a) + log(b)) = Q \\
						(log(a) + log(b)) \& Q + (log(a) + log(b)) >> w & \textrm{otherwises}
						\end{array} \right.
						\end{equation*}
						</p>
						</small>
						<p>
						We can extend the exponential table to make sure exp[Q] = 0.
						</p>
					</section>
					<section>
						<h2>Log&Exp Table Method - Improvement I</h2>
						<small>e.g. Implementation of log-exp table method (improvement I) in $GF(2^8)$:</small>
						<pre><code class="cpp" data-trim contenteditable>
uint8_t gf256_log_table[256];
uint8_t gf256_exp_table[257];
// width of GF(2^8)
const int width = 8;
// number of elements in GF(2^8)
const int NW = 1 << width;
uint8_t gf256_mul(uint8_t a, uint8_t b)
{
  int result;
  if (a == 0 || b == 0)
  {
    return 0;
  }
  result = (gf256_log_table[a] + gf256_log_table[b]) & (NW-1) + (gf256_log_table[a] + gf256_log_table[b]) >> width;
  return gf256_exp_table[result];
}
						</code></pre>
					</section>
					<section>
						<h2>Log&Exp Table Method - Improvement II</h2>
						<p>
						Remove expensive MOD operation by extending the exponential table.
						</p>
						<p>
						Let $Q = 2^w$, then
						$exp[i] = exp[i \% Q] (i \in [Q, 2Q-2])$
						</p>
						<p>
						This improved method is adopted by Jerasure as the LOGS multiplication policy.
						</p>
						<small>e.g. Implementation of log-exp table method (improvement II) in $GF(2^8)$:</small>
						<pre><code class="cpp" data-trim contenteditable>
uint8_t gf256_log_table[256];
uint8_t gf256_exp_table[510];
uint8_t gf256_mul(uint8_t a, uint8_t b)
{
  int result;
  if (a == 0 || b == 0)
  {
    return 0;
  }
  result = (gf256_log_table[a] + gf256_log_table[b]);
  return gf256_exp_table[result];
}
						</code></pre>
					</section>
					<section>
						<h2>Log&Exp Table Method - Improvement III</h2>
						Remove expensive MOD and branch operations by extending the exponential and logarithm tables.
						<p>
						Let $Q = 2^w$, $\alpha$ be the primitive element, then
						<br>
						\begin{equation*}
						exp[i] = \left\{
						\begin{array}{ll}
						\alpha^{i} & \textrm{if } i \in [0, Q-1] \\
						exp[i \% Q] & \textrm{if } i \in [Q, 2Q-1] \\
						0 & \textrm{if } i \in [2Q, 4Q]
						\end{array} \right.
						\end{equation*}
						<br>
						\begin{equation*}
						log[x] = \left\{
						\begin{array}{ll}
						2Q & \textrm{if } x = 0 \\
						i & \textrm{if } x \in [1, Q], x = \alpha^{i}
						\end{array} \right.
						\end{equation*}
						</p>
					</section>
					<section>
						<h2>Log&Exp Table Method - Improvement III</h2>
						<small>e.g. Implementation of log-exp table method (improvement II) in $GF(2^8)$:</small>
						<pre><code class="cpp" data-trim contenteditable>
uint8_t gf256_log_table[257];
uint8_t gf256_exp_table[1024];
uint8_t gf256_mul(uint8_t a, uint8_t b)
{
  int result;
  result = (gf256_log_table[a] + gf256_log_table[b]);
  return gf256_exp_table[result];
}
						</code></pre>
					</section>
				</section>

				<section>
					<section>
						<h2>Accelerate Encoding Matrix Generation</h2>
						<p>
						We use Vandermonde’s Matrix as the encoding matrix.
						The generation of encoding matrix can be paralleled in GPU by letting every thread compute few items of Vandermonde’s Matrix.
						</p>
					</section>
				</section>

				<section>
					<section>
						<h2>Accelerate Encoding/Decoding (Matrix Multiplication)</h2>
						<p>
Tile algorithm is used to
improve the temporary locality and reduce cache misses when an array is accessed in a row major order and in a column major order at the same time.
						</p>
					</section>
					<section>
						<h2>Accelerate Encoding/Decoding (Matrix Multiplication)</h2>
						<img src="./images/matrix-multiplication-without-shared-memory.png">
					</section>
					<section>
						<h2>Accelerate Encoding/Decoding (Matrix Multiplication)</h2>
						<img src="./images/matrix-multiplication-with-shared-memory.png">
					</section>
				</section>
				<section>
					<section>
						<h2>Accelerate Decoding Matrix Generation (Matrix Inversion)</h2>
						<p>
After knowing which $k$ fragments are used for decoding, we know the corresponding rows of coefficients in the encoding matrix $V$ . These rows form the $k \times k$ matrix $V′$ , and we need to compute its inverse. 
						</p>
						<p>
We use Gauss elimination to compute inverse matrix: augment the square matrix $V′$
with the identity matrix $I$ of the same dimensions to obtain $[V′ | I]$ and then
apply matrix operations to transfer $[V′ | I]$ into its reduced row echelon form:
$V′^{−1} [V′ | I] = [I | V′^{−1}]$.
						</p>
					</section>
					<section>
						<h2>Accelerate Decoding Matrix Generation (Matrix Inversion)</h2>
						<p>
Gauss elimination contains the following steps:
<ol>
				<li>
				Check whether the diagonal item in the current row of $V$ is nonzero. If it is zero, find a nonzero item and switch the two columns. The same column switching should also apply to $I$. Then the diagonal item in the current row of $V′$ is our pivot.
				</li>
				<li>
				Normalize the current row by the pivot.
				</li>
				<li>
				Eliminate other rows so that the reverse column of the current row becomes reduced echelon form.
				</li>
</ol>
						</p>
						<p>
Step 2 and Step 3 are suitable to be parallelized, but since we have
to set barriers between steps, Gauss elimination is still not a fully-paralleled
algorithm. CPU-GPU corporation may be an appropriate solution.
						</p>
					</section>
				</section>
				<section>
					<section>
						<h2>Reduce CPU-GPU Communication Overhead</h2>
						<p>
						Use CUDA stream to overlap data transfers with kernel execution.
						<br>
						<img src="./images/timeline-comparison-for-copy-and-kernel-execution.png" src="CUDA-stream">
						<br> Sequential vs. Concurrent copy and execute
						</p>
					</section>
					<section>
						<h2>Reduce CPU-GPU Communication Overhead</h2>
						<p>
						Access host memory directly from within a kernel (Unified Virtual Address Space).
						</p>
					</section>
				</section>

				<section>
				<h2>Future Work & Schedule</h2>
				<ul>
				<li>
Improve the performance of Galois Field operations (we might have several policies for different fields like Jeasure). (2 weeks)
				</li>
				<li>
Improve the performance of matrix multiplication by taking better advantage of the GPU memory hierarchy (parameter tuning).
				</li>
				<li>
There is a faster method for inversing the Vandermonde matrix, but we still need to check whether it is correct in the Galois Field. (1-2 weeks)
				</li>
				<li>
Increase the parallelism of the general matrix inversion algorithm. (a bit challenging for a GPU-only solution) 
				</li>
				<li>
Test whether it is better to solve decoding equations than compute the decoding matrix. (1 month)
				</li>
				<li>
CUDA streams (Previous test has showed performance degradation). (3 weeks)
				</li>
				<li>
Achieve better CPU/GPU cooperation: (1 month)
<ul>
<li>				
While GPU is computing the encoding matrix, CPU can load the
input file(s) into memory, thus making the IO and computation processing roughly at the same time.
</li>
<li>
Find the bound of file size under which CPU performance is better than that of GPU.
</li>
</ul>
				</li>
				</ul>
				</section>

				<section>
					<h1>THE END</h1>
					<h3>Q & A</h3>
				</section>

			</div>

		</div>

		<script src="lib/js/head.min.js"></script>
		<script src="js/reveal.min.js"></script>

		<script>

			// Full list of configuration options available here:
			// https://github.com/hakimel/reveal.js#configuration
			Reveal.initialize({
				controls: true,
				progress: true,
				history: true,
				center: true,

				theme: Reveal.getQueryHash().theme, // available themes are in /css/theme
				transition: Reveal.getQueryHash().transition || 'default', // default/cube/page/concave/zoom/linear/fade/none

//				math: {
//				    mathjax: 'http://cdn.mathjax.org/mathjax/latest/MathJax.js',
//				    config: 'TeX-AMS_HTML-full'  // See http://docs.mathjax.org/en/latest/config-files.html
//				},

				// Optional libraries used to extend on reveal.js
				dependencies: [
					{ src: 'lib/js/classList.js', condition: function() { return !document.body.classList; } },
					{ src: 'plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } },
					{ src: 'plugin/zoom-js/zoom.js', async: true, condition: function() { return !!document.body.classList; } },
					{ src: 'plugin/notes/notes.js', async: true, condition: function() { return !!document.body.classList; } },
					{ src: 'plugin/math/math.js', async: true }
				]
			});

		</script>

<a href="https://github.com/yszheda/GPU-RSCode"><img style="position: absolute; top: 0; left: 0; border: 0;" src="https://s3.amazonaws.com/github/ribbons/forkme_left_darkblue_121621.png" alt="Fork GPU-RSCode on GitHub"></a>

	</body>
</html>
